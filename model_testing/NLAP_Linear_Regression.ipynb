{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ---- Install and Import Necessary Libraries ----\n",
        "!pip install datasets pandas numpy scikit-learn statsmodels nltk tqdm tensorflow\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import nltk\n",
        "\n",
        "# ---- Configure Logging ----\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    filename='model_evaluation.log',\n",
        "    filemode='w',\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "# ---- Suppress Warnings ----\n",
        "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
        "\n",
        "# ---- Download Necessary NLTK Data ----\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# ---- Load the Dataset ----\n",
        "print(\"Loading the dataset...\")\n",
        "logging.info(\"Loading the dataset...\")\n",
        "ds = load_dataset(\"nbettencourt/SC454k\")\n",
        "df = pd.DataFrame(ds['train'])\n",
        "\n",
        "# Display initial data\n",
        "print(\"\\nInitial DataFrame Head:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataFrame Columns:\")\n",
        "print(df.columns)\n",
        "logging.info(f\"Initial DataFrame Head:\\n{df.head()}\")\n",
        "logging.info(f\"DataFrame Columns:\\n{df.columns}\")\n",
        "\n",
        "# ---- Data Preprocessing ----\n",
        "\n",
        "# Handle Missing Values\n",
        "# Drop rows where the target 'weighted_avg_720_hrs' or 'weighted_avg_0_hrs' is missing or zero\n",
        "df = df.dropna(subset=['weighted_avg_720_hrs', 'weighted_avg_0_hrs'])\n",
        "df = df[df['weighted_avg_0_hrs'] != 0]\n",
        "\n",
        "# Parse 'Date' Column\n",
        "# Remove ' ET' from 'Date' strings if present and parse to datetime\n",
        "df['Date_cleaned'] = df['Date'].astype(str).str.replace(' ET', '', regex=False)\n",
        "df['Date'] = pd.to_datetime(df['Date_cleaned'], errors='coerce')\n",
        "df = df.drop(columns=['Date_cleaned'])\n",
        "\n",
        "# Drop rows with unparsed dates\n",
        "df = df.dropna(subset=['Date'])\n",
        "\n",
        "# Convert 'Date' to Unix Timestamp\n",
        "# Convert 'Date' to Unix timestamp (seconds since epoch)\n",
        "df['Date_unix'] = df['Date'].astype('int64') // 10**9\n",
        "\n",
        "# Verify 'Date_unix' creation\n",
        "print(\"\\nDataFrame with 'Date_unix':\")\n",
        "print(df[['Date', 'Date_unix']].head())\n",
        "logging.info(f\"DataFrame with 'Date_unix':\\n{df[['Date', 'Date_unix']].head()}\")\n",
        "\n",
        "# 6.4: Feature Selection\n",
        "# Define numeric and categorical features\n",
        "numeric_features = [\n",
        "    'weighted_avg_-96_hrs',\n",
        "    'weighted_avg_-48_hrs',\n",
        "    'weighted_avg_-24_hrs',\n",
        "    'weighted_avg_0_hrs',\n",
        "    'Risk_Free_Rate',\n",
        "    'Date_unix'\n",
        "]\n",
        "\n",
        "# Add 'Author' and 'Publication' to categorical features\n",
        "categorical_features = ['Symbol', 'Sector', 'Industry', 'Author', 'Publication']\n",
        "\n",
        "# Define text features\n",
        "text_features = ['Title', 'Article']\n",
        "\n",
        "target = 'weighted_avg_720_hrs'\n",
        "\n",
        "required_columns = numeric_features + categorical_features + text_features + [target]\n",
        "missing_cols = set(required_columns) - set(df.columns)\n",
        "if missing_cols:\n",
        "    print(f\"\\nMissing columns in DataFrame: {missing_cols}\")\n",
        "    logging.warning(f\"Missing columns in DataFrame: {missing_cols}\")\n",
        "else:\n",
        "    print(\"\\nAll required columns are present.\")\n",
        "    logging.info(\"All required columns are present.\")\n",
        "\n",
        "# Remove Sentiment Scoring\n",
        "# Sentiment scoring is removed as it did not improve performance\n",
        "\n",
        "# ---- Train-Test Split ----\n",
        "# Sort the DataFrame by 'Date' to maintain chronological order\n",
        "df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# Determine split indices\n",
        "total_length = len(df)\n",
        "train_size = int(total_length * 0.70)  # 70% for training\n",
        "test_size = int(total_length * 0.15)   # 15% for testing\n",
        "# update_size = total_length - train_size - test_size  # 15% for updating (not used here)\n",
        "\n",
        "# Split the data\n",
        "train_df = df.iloc[:train_size].reset_index(drop=True)\n",
        "test_df = df.iloc[train_size:train_size + test_size].reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nTraining Set Size: {train_df.shape}\")\n",
        "print(f\"Testing Set Size: {test_df.shape}\")\n",
        "logging.info(f\"Training Set Size: {train_df.shape}\")\n",
        "logging.info(f\"Testing Set Size: {test_df.shape}\")\n",
        "\n",
        "# Define training and testing features and targets\n",
        "X_train = train_df[numeric_features + categorical_features + text_features].copy()\n",
        "y_train = train_df[target].copy()\n",
        "\n",
        "X_test = test_df[numeric_features + categorical_features + text_features].copy()\n",
        "y_test = test_df[target].copy()\n",
        "\n",
        "# ---- Build the Preprocessing Pipeline ----\n",
        "# Preprocessing for numeric features: Standard Scaling\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Preprocessing for categorical features: One-Hot Encoding\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Preprocessing for text features: TF-IDF Vectorization\n",
        "title_transformer = Pipeline(steps=[\n",
        "    ('tfidf', TfidfVectorizer(max_features=500))\n",
        "])\n",
        "\n",
        "article_transformer = Pipeline(steps=[\n",
        "    ('tfidf', TfidfVectorizer(max_features=1000))\n",
        "])\n",
        "\n",
        "# Combine preprocessing for numeric, categorical, and text features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features),\n",
        "        ('title_tfidf', title_transformer, 'Title'),\n",
        "        ('article_tfidf', article_transformer, 'Article')\n",
        "    ])\n",
        "\n",
        "# ---- Create and Train the Linear Regression Model ----\n",
        "# Create the Pipeline with preprocessing and Linear Regression\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Fit the model on the training data\n",
        "print(\"\\nTraining the Linear Regression model...\")\n",
        "logging.info(\"Training the Linear Regression model...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training completed.\")\n",
        "logging.info(\"Model training completed.\")\n",
        "\n",
        "# ---- Make Predictions and Evaluate the Model ----\n",
        "# Make predictions on the test set\n",
        "print(\"\\nMaking predictions on the test set...\")\n",
        "logging.info(\"Making predictions on the test set...\")\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# ---- Compute Additional Metrics ----\n",
        "\n",
        "# Calculate Actual and Predicted Returns\n",
        "# 'weighted_avg_0_hrs' is the current price at the time of the article's release\n",
        "test_df['Actual_Return'] = (test_df['weighted_avg_720_hrs'] / test_df['weighted_avg_0_hrs']) - 1\n",
        "test_df['Predicted_Return'] = (y_pred / test_df['weighted_avg_0_hrs']) - 1\n",
        "\n",
        "# Remove any remaining NaN or infinite values\n",
        "test_df = test_df.replace([np.inf, -np.inf], np.nan).dropna(subset=['Actual_Return', 'Predicted_Return'])\n",
        "\n",
        "# Calculate Overall MSE, RMSE, and R2 on Returns\n",
        "overall_mse_returns = mean_squared_error(test_df['Actual_Return'], test_df['Predicted_Return'])\n",
        "overall_rmse_returns = np.sqrt(overall_mse_returns)\n",
        "overall_r2_returns = r2_score(test_df['Actual_Return'], test_df['Predicted_Return'])\n",
        "\n",
        "print(\"\\nLinear Regression Model Performance on Returns:\")\n",
        "print(f\"Mean Squared Error (MSE): {overall_mse_returns:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {overall_rmse_returns:.4f}\")\n",
        "print(f\"R-squared (R2 ): {overall_r2_returns:.4f}\")\n",
        "\n",
        "logging.info(\"Linear Regression Model Performance on Returns:\")\n",
        "logging.info(f\"Mean Squared Error (MSE): {overall_mse_returns:.4f}\")\n",
        "logging.info(f\"Root Mean Squared Error (RMSE): {overall_rmse_returns:.4f}\")\n",
        "logging.info(f\"R-squared (R2 ): {overall_r2_returns:.4f}\")\n",
        "\n",
        "# Define Strategy Return\n",
        "# Strategy: Long position if Predicted_Return > 0, else no position\n",
        "test_df['Strategy_Return'] = np.where(test_df['Predicted_Return'] > 0, test_df['Actual_Return'], 0)\n",
        "\n",
        "# Sector Metrics (MSE, R2, and Sharpe Ratio per Sector)\n",
        "sector_metrics = {}\n",
        "\n",
        "for sector in test_df['Sector'].unique():\n",
        "    sector_data = test_df[test_df['Sector'] == sector].copy()\n",
        "    sector_data = sector_data.dropna(subset=['Actual_Return', 'Predicted_Return'])\n",
        "    if len(sector_data) == 0:\n",
        "        sector_metrics[sector] = {'mse': np.nan, 'r2': np.nan, 'sharpe': np.nan}\n",
        "    else:\n",
        "        mse_sector = mean_squared_error(sector_data['Actual_Return'], sector_data['Predicted_Return'])\n",
        "        r2_sector = r2_score(sector_data['Actual_Return'], sector_data['Predicted_Return'])\n",
        "\n",
        "        # Calculate Sharpe Ratio\n",
        "        strategy_excess_return = sector_data['Strategy_Return'] - sector_data['Risk_Free_Rate']\n",
        "        if strategy_excess_return.std() != 0:\n",
        "            sharpe_ratio = strategy_excess_return.mean() / strategy_excess_return.std()\n",
        "        else:\n",
        "            sharpe_ratio = np.nan  # Undefined if no variation\n",
        "\n",
        "        sector_metrics[sector] = {'mse': mse_sector, 'r2': r2_sector, 'sharpe': sharpe_ratio}\n",
        "\n",
        "# Convert sector metrics to DataFrame\n",
        "sector_metrics_df = pd.DataFrame.from_dict(sector_metrics, orient='index').reset_index()\n",
        "sector_metrics_df = sector_metrics_df.rename(columns={'index': 'Sector'})\n",
        "print(\"\\nSector-wise Metrics (on Returns):\")\n",
        "print(sector_metrics_df)\n",
        "\n",
        "logging.info(\"Sector-wise Metrics (on Returns):\")\n",
        "logging.info(f\"{sector_metrics_df}\")\n",
        "\n",
        "# Overall Trend Accuracy\n",
        "# Calculate the direction of actual and predicted returns\n",
        "test_df['Actual_Direction'] = np.where(test_df['Actual_Return'] > 0, 1, 0)\n",
        "test_df['Predicted_Direction'] = np.where(test_df['Predicted_Return'] > 0, 1, 0)\n",
        "\n",
        "# Calculate accuracy of direction predictions\n",
        "overall_trend_acc = (test_df['Actual_Direction'] == test_df['Predicted_Direction']).mean()\n",
        "\n",
        "print(f\"\\nOverall Trend Accuracy: {overall_trend_acc:.2%}\")\n",
        "logging.info(f\"Overall Trend Accuracy: {overall_trend_acc:.2%}\")\n",
        "\n",
        "# Sharpe Ratio\n",
        "# Assuming 'Risk_Free_Rate' is per period (e.g., monthly)\n",
        "# Calculate excess returns for the strategy\n",
        "test_df['Strategy_Excess_Return'] = test_df['Strategy_Return'] - test_df['Risk_Free_Rate']\n",
        "\n",
        "# Calculate Sharpe Ratio\n",
        "# Handle case where standard deviation is zero\n",
        "if test_df['Strategy_Excess_Return'].std() != 0:\n",
        "    sharpe_ratio = test_df['Strategy_Excess_Return'].mean() / test_df['Strategy_Excess_Return'].std()\n",
        "else:\n",
        "    sharpe_ratio = np.nan  # Undefined if no variation\n",
        "\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
        "logging.info(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
        "\n",
        "# Sortino Ratio\n",
        "# Define target return as 0 for downside deviation\n",
        "target_return = 0\n",
        "downside_returns = test_df['Strategy_Return'][test_df['Strategy_Return'] < target_return]\n",
        "downside_deviation = downside_returns.std()\n",
        "\n",
        "# Handle case where downside_deviation is zero\n",
        "if downside_deviation != 0:\n",
        "    sortino_ratio = (test_df['Strategy_Return'].mean() - test_df['Risk_Free_Rate'].mean()) / downside_deviation\n",
        "else:\n",
        "    sortino_ratio = np.nan  # Undefined if no downside deviation\n",
        "\n",
        "print(f\"Sortino Ratio: {sortino_ratio:.4f}\")\n",
        "logging.info(f\"Sortino Ratio: {sortino_ratio:.4f}\")\n",
        "\n",
        "# Average Return\n",
        "average_return = test_df['Strategy_Return'].mean()\n",
        "\n",
        "print(f\"Average Strategy Return: {average_return:.4f}\")\n",
        "logging.info(f\"Average Strategy Return: {average_return:.4f}\")\n",
        "\n",
        "# Win Rate\n",
        "# Calculate the proportion of profitable strategy returns\n",
        "wins = test_df['Strategy_Return'] > 0\n",
        "win_rate = wins.mean()\n",
        "\n",
        "print(f\"Win Rate: {win_rate:.2%}\")\n",
        "logging.info(f\"Win Rate: {win_rate:.2%}\")\n",
        "\n",
        "# Profit Factor\n",
        "# Calculate gross profits and gross losses\n",
        "gross_profit = test_df.loc[test_df['Strategy_Return'] > 0, 'Strategy_Return'].sum()\n",
        "gross_loss = -test_df.loc[test_df['Strategy_Return'] < 0, 'Strategy_Return'].sum()\n",
        "\n",
        "# Handle division by zero\n",
        "if gross_loss != 0:\n",
        "    profit_factor = gross_profit / gross_loss\n",
        "else:\n",
        "    profit_factor = np.inf  # Infinite profit factor if no losses\n",
        "\n",
        "print(f\"Profit Factor: {profit_factor:.4f}\")\n",
        "logging.info(f\"Profit Factor: {profit_factor:.4f}\")\n",
        "\n",
        "# ---- Print and Log Per-Sector Metrics ----\n",
        "print(\"\\nPer-Sector Metrics:\")\n",
        "logging.info(\"Per-Sector Metrics:\")\n",
        "\n",
        "for index, row in sector_metrics_df.iterrows():\n",
        "    sector = row['Sector']\n",
        "    mse_sector = row['mse']\n",
        "    r2_sector = row['r2']\n",
        "    sharpe_sector = row['sharpe']\n",
        "\n",
        "    # Print sector metrics\n",
        "    print(\n",
        "        f\"Sector: {sector} - \"\n",
        "        f\"MSE: {mse_sector:.4f}, \"\n",
        "        f\"R²: {r2_sector:.4f}, \"\n",
        "        f\"Sharpe Ratio: {sharpe_sector:.4f}\"\n",
        "    )\n",
        "\n",
        "    # Log sector metrics\n",
        "    logging.info(\n",
        "        f\"Sector: {sector} - \"\n",
        "        f\"MSE: {mse_sector:.4f}, \"\n",
        "        f\"R²: {r2_sector:.4f}, \"\n",
        "        f\"Sharpe Ratio: {sharpe_sector:.4f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBq-PjxpdC6q",
        "outputId": "5f7e0c51-45b0-41ce-f72a-cdcab59214d7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial DataFrame Head:\n",
            "  Symbol                            Security                  Sector  \\\n",
            "0    UTL                  Unitil Corporation               Utilities   \n",
            "1     HE  Hawaiian Electric Industries, Inc.               Utilities   \n",
            "2     MG                 Mistras Group, Inc.  Consumer Discretionary   \n",
            "3    GNK    Genco Shipping & Trading Limited  Consumer Discretionary   \n",
            "4     BB                  BlackBerry Limited              Technology   \n",
            "\n",
            "                                  Industry  \\\n",
            "0                         Power Generation   \n",
            "1              Electric Utilities: Central   \n",
            "2            Military/Government/Technical   \n",
            "3                    Marine Transportation   \n",
            "4  Computer Software: Prepackaged Software   \n",
            "\n",
            "                                                 URL                 Date  \\\n",
            "0  https://www.nasdaq.com/articles/safest-high-yi...  2009-10-09 11:48:00   \n",
            "1  https://www.nasdaq.com/articles/safest-high-yi...  2009-10-09 11:48:00   \n",
            "2  https://www.nasdaq.com/articles/mistras-group-...  2009-10-09 11:49:00   \n",
            "3  https://www.nasdaq.com/articles/four-shippers-...  2009-10-22 02:42:00   \n",
            "4  https://www.nasdaq.com/articles/review-spains-...  2009-10-25 12:39:00   \n",
            "\n",
            "                               RelatedStocksList  \\\n",
            "0                             Markets|PNW|DTE|HE   \n",
            "1                            UTL|Markets|PNW|DTE   \n",
            "2  ERJ|Markets|BP|BAC|XOM|GE|PFE|VLO|JPM|CVX|AEP   \n",
            "3                       Markets|EGLE|NM|ESEA|DSX   \n",
            "4                                VOD|Markets|TEF   \n",
            "\n",
            "                                             Article  \\\n",
            "0  If you think \"widow and orphan\" utility stocks...   \n",
            "1  If you think \"widow and orphan\" utility stocks...   \n",
            "2  [Abbi Adest](http://seekingalpha.com/by/author...   \n",
            "3  ** [Andy Wang](http://www.philstockworld.com/w...   \n",
            "4  It's impressive to see how the Spanish industr...   \n",
            "\n",
            "                                               Title articleType  ...  \\\n",
            "0           The Safest High-Yield Electric Utilities        News  ...   \n",
            "1           The Safest High-Yield Electric Utilities        News  ...   \n",
            "2                Mistras Group Has Another Go at IPO        News  ...   \n",
            "3               Four Shippers Emerging from the Mire        News  ...   \n",
            "4  Review of Spain's Fixed Line and Broadband Market        News  ...   \n",
            "\n",
            "  weighted_avg_4_hrs weighted_avg_6_hrs  weighted_avg_8_hrs  \\\n",
            "0            22.8694            22.8612             22.8612   \n",
            "1            18.7710            19.0138             19.0138   \n",
            "2            12.7029            12.6735             12.6735   \n",
            "3            22.7856            22.8215             22.6351   \n",
            "4             0.0000             0.0000              0.0000   \n",
            "\n",
            "   weighted_avg_12_hrs  weighted_avg_24_hrs  weighted_avg_48_hrs  \\\n",
            "0              22.8612              22.8677              22.9235   \n",
            "1              19.0138              19.0152              18.8444   \n",
            "2              12.6735              12.6850              12.7682   \n",
            "3              23.4916              23.8206              22.5641   \n",
            "4               0.0000               0.0000               0.0000   \n",
            "\n",
            "   weighted_avg_72_hrs  weighted_avg_96_hrs  weighted_avg_360_hrs  \\\n",
            "0              22.8674              23.0707               22.5042   \n",
            "1              18.9600              18.8013               23.7980   \n",
            "2              12.8303              12.9391               13.0015   \n",
            "3              22.5332              22.5305               19.8162   \n",
            "4               0.0000               0.0000                0.0000   \n",
            "\n",
            "   weighted_avg_720_hrs  \n",
            "0               19.9395  \n",
            "1               19.1804  \n",
            "2               12.2407  \n",
            "3               25.3433  \n",
            "4                0.0000  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "DataFrame Columns:\n",
            "Index(['Symbol', 'Security', 'Sector', 'Industry', 'URL', 'Date',\n",
            "       'RelatedStocksList', 'Article', 'Title', 'articleType', 'Publication',\n",
            "       'Author', 'Risk_Free_Rate', 'weighted_avg_-96_hrs',\n",
            "       'weighted_avg_-48_hrs', 'weighted_avg_-24_hrs', 'weighted_avg_0_hrs',\n",
            "       'weighted_avg_0.25_hrs', 'weighted_avg_0.50_hrs', 'weighted_avg_1_hrs',\n",
            "       'weighted_avg_2_hrs', 'weighted_avg_4_hrs', 'weighted_avg_6_hrs',\n",
            "       'weighted_avg_8_hrs', 'weighted_avg_12_hrs', 'weighted_avg_24_hrs',\n",
            "       'weighted_avg_48_hrs', 'weighted_avg_72_hrs', 'weighted_avg_96_hrs',\n",
            "       'weighted_avg_360_hrs', 'weighted_avg_720_hrs'],\n",
            "      dtype='object')\n",
            "\n",
            "DataFrame with 'Date_unix':\n",
            "                 Date   Date_unix\n",
            "0 2009-10-09 11:48:00  1255088880\n",
            "1 2009-10-09 11:48:00  1255088880\n",
            "2 2009-10-09 11:49:00  1255088940\n",
            "3 2009-10-22 02:42:00  1256179320\n",
            "5 2009-10-27 10:39:00  1256639940\n",
            "\n",
            "All required columns are present.\n",
            "\n",
            "Training Set Size: (308789, 32)\n",
            "Testing Set Size: (66169, 32)\n",
            "\n",
            "Training the Linear Regression model...\n",
            "Model training completed.\n",
            "\n",
            "Making predictions on the test set...\n",
            "\n",
            "Linear Regression Model Performance on Returns:\n",
            "Mean Squared Error (MSE): 1.1258\n",
            "Root Mean Squared Error (RMSE): 1.0610\n",
            "R-squared (R2 ): -1.0390\n",
            "\n",
            "Sector-wise Metrics (on Returns):\n",
            "                    Sector        mse         r2    sharpe\n",
            "0              Health Care   0.745400  -3.326091 -0.178546\n",
            "1   Consumer Discretionary   0.600583  -1.388770 -0.108604\n",
            "2               Technology   1.190968  -1.741278 -0.062904\n",
            "3                   Energy   0.099726  -1.843616 -0.437280\n",
            "4              Industrials   0.595500  -1.049054 -0.307585\n",
            "5              Real Estate   0.327840  -0.290708  0.087620\n",
            "6                  Finance   2.249061  -1.283795 -0.005760\n",
            "7       Telecommunications  18.840371  -0.234314  0.060239\n",
            "8         Consumer Staples   0.154604  -3.774936 -0.648213\n",
            "9                Utilities   0.883541   0.143736  0.112608\n",
            "10         Basic Materials   0.508069 -15.869607 -0.644630\n",
            "11           Miscellaneous   3.986545  -2.138274  0.128798\n",
            "12                 Unknown   0.164021  -1.922381 -0.705001\n",
            "\n",
            "Overall Trend Accuracy: 55.20%\n",
            "Sharpe Ratio: -0.0533\n",
            "Sortino Ratio: -0.2147\n",
            "Average Strategy Return: 0.0218\n",
            "Win Rate: 13.16%\n",
            "Profit Factor: 2.0544\n",
            "\n",
            "Per-Sector Metrics:\n",
            "Sector: Health Care - MSE: 0.7454, R²: -3.3261, Sharpe Ratio: -0.1785\n",
            "Sector: Consumer Discretionary - MSE: 0.6006, R²: -1.3888, Sharpe Ratio: -0.1086\n",
            "Sector: Technology - MSE: 1.1910, R²: -1.7413, Sharpe Ratio: -0.0629\n",
            "Sector: Energy - MSE: 0.0997, R²: -1.8436, Sharpe Ratio: -0.4373\n",
            "Sector: Industrials - MSE: 0.5955, R²: -1.0491, Sharpe Ratio: -0.3076\n",
            "Sector: Real Estate - MSE: 0.3278, R²: -0.2907, Sharpe Ratio: 0.0876\n",
            "Sector: Finance - MSE: 2.2491, R²: -1.2838, Sharpe Ratio: -0.0058\n",
            "Sector: Telecommunications - MSE: 18.8404, R²: -0.2343, Sharpe Ratio: 0.0602\n",
            "Sector: Consumer Staples - MSE: 0.1546, R²: -3.7749, Sharpe Ratio: -0.6482\n",
            "Sector: Utilities - MSE: 0.8835, R²: 0.1437, Sharpe Ratio: 0.1126\n",
            "Sector: Basic Materials - MSE: 0.5081, R²: -15.8696, Sharpe Ratio: -0.6446\n",
            "Sector: Miscellaneous - MSE: 3.9865, R²: -2.1383, Sharpe Ratio: 0.1288\n",
            "Sector: Unknown - MSE: 0.1640, R²: -1.9224, Sharpe Ratio: -0.7050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57LQvl52QjmM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}